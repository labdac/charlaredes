{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción a redes neuronales\n",
    "\n",
    "![Logo Laboratorio](images/labdac_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Idea de la charla   \n",
    "\n",
    "* Motivar las redes neuronales como modelos predictivos\n",
    "* Presentar las distintas topologías y tipos\n",
    "* Comentar un poco la literatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### ¿Cómo definimos un modelo?  \n",
    "* Planteamos una hipótesis\n",
    "* Definimos qué es un buen modelo\n",
    "* Intentamos llegar a uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ¿Cómo definimos un modelo? (Versión matemática)\n",
    "* Planteamos una función predictora\n",
    "* Definimos una función de error (o *costo*)\n",
    "* Minimizamos el costo con métodos numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funciones predictoras  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Generalmente dos tipos\n",
    " + de regresión\n",
    " + de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* tienen parámetros\n",
    " + algunos se _aprenden_ (calculados según los datos)\n",
    " + otros los decidimos nosotros a priori, con intuición o probando (*hiperparámetros*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Función error/costo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* permite medir cuán bueno (o malo) es el modelo\n",
    "* implícitamente nos dice cómo mejorarlo (¡derivando!)\n",
    "* ejemplo para regresión:  \n",
    "\n",
    "$$ MSE(X,Y) = \\sum_i (Y_i - X_i)^2 $$\n",
    "* ejemplo para clasificación:     \n",
    "\n",
    "$$ \\mathcal{L}(\\theta|x) \\equiv P(x|\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimización: reduciendo el error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Análisis I: derivando, igualo a 0, calculo los puntos de mínimo\n",
    "* Ahora, no siempre es sencillo (o posible) resolverlo de manera analítica, entonces necesitamos un método numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Usamos *descenso de gradiente*\n",
    " + dado un campo escalar \n",
    " \n",
    "$$f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    " + y su gradiente:\n",
    "\n",
    "$$\\bar{\\nabla}f(\\bar{x}) = \\left (\n",
    "    \\frac{\\partial f}{\\partial x_1},\n",
    "    ...,\n",
    "    \\frac{\\partial f}{\\partial x_n}\n",
    "\\right )\n",
    "$$\n",
    " + podemos minimizar x iterativamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\bar{x}^{t+1} =  \\bar{x}^t - \\bar{\\nabla}f(\\bar{x}^t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comentario: pequeño truquito (SGD)\n",
    "* el gradiente se calcula sobre todos los datos\n",
    "* pero si tenemos millones de datos.. ¡eso es lento!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* entonces lo calculamos sobre unos pocos datos: **Descenso de gradiente estocástico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualización  \n",
    "![Visualizacion de distintos SGD](images/sgd.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Links y referencias  \n",
    "* Visualizaciones súper copadas y comparación de optimizaciones: [Why momentum really works](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* super sencillo\n",
    "* hipotesis: \n",
    "$$ y = f(x) = mx + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![grafico de regresion lineal](images/linear_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* hipótesis generalizada:    \n",
    "\n",
    "$$ h_{\\theta}(\\bar{x}) = \\theta^t \\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* usamos el error cuadrático:  \n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2} \\sum_i \\left ( h_\\theta(x^{(i)}) - y^{(i)} \\right )^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* derivamos:   \n",
    "\n",
    "$$ \\bar{\\nabla} J(\\theta) = \\sum_i \\left ( h_\\theta(x^{(i)}) - y^{(i)}) \\theta \\right )  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* tenemos nuestra receta:     \n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\bar{\\nabla}J(\\theta_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualización \n",
    "![grafo de regresión lineal](images/grafo_regresion_lineal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo de código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#contratar un mono que lo programe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión logística\n",
    "* queremos transformar nuestra regresión lineal para que prediga una variable binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* teníamos una función \n",
    "$$f_{regr}: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    "* ahora queremos \n",
    "$$f_{clasif}: \\mathbb{R}^n \\rightarrow [0,1]$$  \n",
    "* esto lo podemos conseguir aplicando una función $\\sigma: \\mathbb{R} \\rightarrow [0,1]$\n",
    "* particularmente estaría bueno que\n",
    " + $\\sigma(x)$ sea fácil de diferenciar\n",
    " + $\\sigma(x)$ sea continua y tenga propiedades lindas\n",
    " + $\\sigma(x)$ sea no lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* *un* candidato es la función logística:   \n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Esta función es buena porque nos permite indicar el grado de incerteza que podemos tener para predecir la clase. \n",
    "![curva sigmoide](images/sigmoid_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Receta de la logística\n",
    "* hipótesis:    \n",
    "\n",
    "$$ P(y=1|x) = h_\\theta(x) = \\frac{1}{1+exp(-\\theta^tx)}$$   \n",
    "\n",
    "$$ P(y=0|x) = 1 - P(y=1|x) = 1 - h_\\theta(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* para definir el costo, usamos la verosimilitud:   \n",
    "\n",
    "$$ \\mathcal{L}(\\theta|x_1\\ ...\\ x_n) = P(x_1\\ ...\\ x_n|\\theta) = P(x_1|\\theta)\\times ... \\times P(x_n|\\theta)$$  \n",
    "\n",
    "entonces:  \n",
    "\n",
    "$$ J(\\theta) = -\\sum_i \\log \\mathcal{L(\\theta|x_i)}$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ J(\\theta) = -\\sum_i \\left ( y_i \\log h_\\theta(x_i) + (1-y_i) \\log(1-h_\\theta(x_i)) \\right )$$\n",
    "  \n",
    "* luego de otra hoja, obtenemos el gradiente:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\bar{\\nabla}J(\\theta) = \\sum_i x_i(h_\\theta(x_i)-y_i)$$   \n",
    "\n",
    "¡bastante sencillo quedó el gradiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Representación de la regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![grafo de la regresión logística](images/graph_logistic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ¡Veamos un ejemplo!\n",
    "** [playground.tensorflow.org](http://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.90322&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión softmax   \n",
    "\n",
    "* queremos generalizar la regresión logística al caso de $k$ clases a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(x|\\theta) = \\binom{\\exp(\\theta_1^t)x}{\\exp(\\theta_2^t)x} \\frac{1}{\\sum_{i=1}^{2} \\exp(\\theta_i^t x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(x|\\theta) = \n",
    "\\begin{pmatrix}\n",
    "\\exp(\\theta_1^tx) \\\\ \n",
    "... \\\\ \n",
    "\\exp(\\theta_k^tx)\n",
    "\\end{pmatrix}\n",
    "\\frac{1}{\\sum_{i=1}^{k} \\exp(\\theta_i^t x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "los vectores $\\theta_i$ son pesos que relacionan la muestra $x$ con la clase $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Función costo\n",
    "\n",
    "Teníamos en la logística:     \n",
    "\n",
    "$$J(\\theta) = - \\sum_i \\left ( y^{(i)} \\log h_\\theta (x^{(i)}) + (1-y^{(i)}) \\    log (1-h_\\theta (x^{(i)})) \\right )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reescribimos:     \n",
    "\n",
    "$$J(\\theta) = - \\sum_i \\sum_{k=1}^2 \\mathrm{1}_{\\{y^{(i)} = k\\}} \\log \\left ( \\frac{\\exp(\\theta_{(k)}^t) x^{(i)}}{\\sum_{j=1}^2 \\exp(\\theta_{(j)}^t) x^{(i)}} \\right )  $$\n",
    "\n",
    "* para un dato $x^{(i)}$, sólo sumamos el error de la clase verdadera del dato (función indicadora)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "¡Generalizamos!:\n",
    "$$J(\\theta) = - \\sum_i \\sum_{k=1}^K \\mathrm{1}_{\\{y^{(i)} = k\\}} \\frac{\\exp(\\theta_{(k)}^t) x^{(i)}}{\\sum_{j=1}^2 \\exp(\\theta_{(j)}^t) x^{(i)}}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* el gradiente simplemente es derivar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "representamos el vector \n",
    "![softmax](images/graph_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo de softmax: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptrón multicapa\n",
    "* Hasta ahora, todo lo que hicimos fue una variación de la regresión lineal. Entonces el límite de separación entre clases (*decision boundary*) son *hiperplanos*. \n",
    "* ¿Cómo manejamos un problema que no es separable por hiperplanos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [veamos un ejemplo](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=1&regularizationRate=0&noise=0&networkShape=&seed=0.27921&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Una manera de resolver esto es cambiar de espacio hacia uno donde sean linealmente separables las clases.\n",
    "* SVM hace esto con proyecciones implícitas a través de kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* queremos una transformación no-lineal que mueva los datos para luego aplicar softmax: $\\mathrm{softmax}(\\phi(x))$\n",
    "\n",
    "\n",
    "![projection](images/projection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* esto lo podemos hacer agregando una capa adicional: \n",
    "\n",
    "![projection_softmax](images/projection_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Agreguemos una capa al playground anterior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* El entrenamiento, que ajusta los pesos, se puede interpretar como lo siguiente:\n",
    " + en la capa última, los pesos se optimizan para separar las clases con hiperplanos.\n",
    " + en la capa intermedia, los pesos cambian para mejorar la representación de las clases, tal que el softmax tenga un trabajo más sencillo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ¿cómo entrenamos esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* observemos que cada capa es una función:\n",
    "![sof](images/sequence_of_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Calculamos los costos para cada capa:   \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{Costo}}{\\mathrm{Capa}_{n-1}}\n",
    "= \n",
    "\\frac{\\partial \\mathrm{Costo}}{\\mathrm{Capa}_{n}} \n",
    "\\times\n",
    "\\frac{\\partial \\mathrm{Capa}_{n}}{\\mathrm{Capa}_{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Para esto se usa el algoritmo de retropropagación (*backpropagation*).\n",
    "\n",
    "3blue1brown, nielsen, colah?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Teorema de aproximación universal\n",
    "* Nos garantiza que con una sola capa oculta de suficiente número de neuronas, podemos representar cualquier función.   \n",
    "\n",
    "* Entonces, un perceptrón multicapa podrá separar cualquier set de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funciones de activación\n",
    "* Una neurona tiene varias entradas y una salida.\n",
    "* La salida es función de la entrada: $\\mathrm{Salida} = \\bar{\\sigma}(\\theta_t x)$\n",
    "* En este contexto $\\sigma$ se llama función de activación. Hasta ahora usamos la función sigmoide, pero hay otras:\n",
    "![activation function](images/activationfunctions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Referencias    \n",
    "Backpropagation: \n",
    "* [Calculus on computational graphs: backpropagation](http://colah.github.io/posts/2015-08-Backprop/), Christopher Olah\n",
    "* [How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html), Michael Nielsen\n",
    "* [What is backpropagation and what is it actually doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U), 3Blue1Brown (video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
