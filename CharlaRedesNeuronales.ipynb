{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción a redes neuronales\n",
    "\n",
    "![Logo Laboratorio](images/labdac_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Idea de la charla   \n",
    "\n",
    "* Motivar las redes neuronales como modelos predictivos\n",
    "* Presentar las distintas topologías y tipos\n",
    "* Comentar un poco la literatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### ¿Cómo definimos un modelo?  \n",
    "* Planteamos una hipótesis\n",
    "* Definimos qué es un buen modelo\n",
    "* Intentamos llegar a uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ¿Cómo definimos un modelo? (Versión matemática)\n",
    "* Planteamos una función predictora\n",
    "* Definimos una función de error (o *costo*)\n",
    "* Minimizamos el costo con métodos numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funciones predictoras  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Generalmente dos tipos\n",
    " + de regresión\n",
    " + de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* tienen parámetros\n",
    " + algunos se _aprenden_ (calculados según los datos)\n",
    " + otros los decidimos nosotros a priori, con intuición o probando (*hiperparámetros*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Función error/costo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* permite medir cuán bueno (o malo) es el modelo\n",
    "* implícitamente nos dice cómo mejorarlo (¡derivando!)\n",
    "* ejemplo para regresión:  \n",
    "\n",
    "$$ MSE(X,Y) = \\sum_i (Y_i - X_i)^2 $$\n",
    "* ejemplo para clasificación:     \n",
    "\n",
    "$$ \\mathcal{L}(\\theta|x) \\equiv P(x|\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimización: reduciendo el error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Análisis I: derivando, igualo a 0, calculo los puntos de mínimo\n",
    "* Ahora, no siempre es sencillo (o posible) resolverlo de manera analítica, entonces necesitamos un método numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Usamos *descenso de gradiente*\n",
    " + dado un campo escalar \n",
    " \n",
    "$$f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    " + y su gradiente:\n",
    "\n",
    "$$\\bar{\\nabla}f(\\bar{x}) = \\left (\n",
    "    \\frac{\\partial f}{\\partial x_1},\n",
    "    ...,\n",
    "    \\frac{\\partial f}{\\partial x_n}\n",
    "\\right )\n",
    "$$\n",
    " + podemos minimizar x iterativamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\bar{x}^{t+1} =  \\bar{x}^t - \\bar{\\nabla}f(\\bar{x}^t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comentario: pequeño truquito (SGD)\n",
    "* el gradiente se calcula sobre todos los datos\n",
    "* pero si tenemos millones de datos.. ¡eso es lento!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* entonces lo calculamos sobre unos pocos datos: **Descenso de gradiente estocástico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualización  \n",
    "![Visualizacion de distintos SGD](images/sgd.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Links y referencias  \n",
    "* Visualizaciones súper copadas y comparación de optimizaciones: [Why momentum really works](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* super sencillo\n",
    "* hipotesis: \n",
    "$$ y = f(x) = mx + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![grafico de regresion lineal](images/linear_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* hipótesis generalizada:    \n",
    "\n",
    "$$ h_{\\theta}(\\bar{x}) = \\theta^t \\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* usamos el error cuadrático:  \n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2} \\sum_i \\left ( h_\\theta(x^{(i)}) - y^{(i)} \\right )^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* derivamos:   \n",
    "\n",
    "$$ \\bar{\\nabla} J(\\theta) = \\sum_i \\left ( h_\\theta(x^{(i)}) - y^{(i)} \\right ) x^{(i)}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* tenemos nuestra receta:     \n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\bar{\\nabla}J(\\theta_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualización \n",
    "![grafo de regresión lineal](images/grafo_regresion_lineal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión logística\n",
    "* queremos transformar nuestra regresión lineal para que prediga una variable binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* teníamos una función \n",
    "$$f_{regr}: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    "* ahora queremos \n",
    "$$f_{clasif}: \\mathbb{R}^n \\rightarrow [0,1]$$  \n",
    "* esto lo podemos conseguir aplicando una función $\\sigma: \\mathbb{R} \\rightarrow [0,1]$\n",
    "* particularmente estaría bueno que\n",
    " + $\\sigma(x)$ sea fácil de diferenciar\n",
    " + $\\sigma(x)$ sea continua y tenga propiedades lindas\n",
    " + $\\sigma(x)$ sea no lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* *un* candidato es la función logística:   \n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Esta función es buena porque nos permite indicar el grado de incerteza que podemos tener para predecir la clase. \n",
    "![curva sigmoide](images/sigmoid_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Receta de la logística\n",
    "* hipótesis:    \n",
    "\n",
    "$$ P(y=1|x) = h_\\theta(x) = \\frac{1}{1+exp(-\\theta^tx)}$$   \n",
    "\n",
    "$$ P(y=0|x) = 1 - P(y=1|x) = 1 - h_\\theta(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* para definir el costo, usamos la verosimilitud:   \n",
    "\n",
    "$$ \\mathcal{L}(\\theta|x_1\\ ...\\ x_n) = P(x_1\\ ...\\ x_n|\\theta) = P(x_1|\\theta)\\times ... \\times P(x_n|\\theta)$$  \n",
    "\n",
    "entonces:  \n",
    "\n",
    "$$ J(\\theta) = -\\sum_i \\log \\mathcal{L(\\theta|x_i)}$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ J(\\theta) = -\\sum_i \\left ( y_i \\log h_\\theta(x_i) + (1-y_i) \\log(1-h_\\theta(x_i)) \\right )$$\n",
    "  \n",
    "* luego de otra hoja, obtenemos el gradiente:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\bar{\\nabla}J(\\theta) = \\sum_i x_i(h_\\theta(x_i)-y_i)$$   \n",
    "\n",
    "¡bastante sencillo quedó el gradiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Representación de la regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![grafo de la regresión logística](images/graph_logistic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ¡Veamos un ejemplo!\n",
    "** [playground.tensorflow.org](http://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.90322&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión softmax   \n",
    "\n",
    "* queremos generalizar la regresión logística al caso de $k$ clases a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(x|\\theta) = \\binom{\\exp(\\theta_1^t)x}{\\exp(\\theta_2^t)x} \\frac{1}{\\sum_{i=1}^{2} \\exp(\\theta_i^t x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(x|\\theta) = \n",
    "\\begin{pmatrix}\n",
    "\\exp(\\theta_1^tx) \\\\ \n",
    "... \\\\ \n",
    "\\exp(\\theta_k^tx)\n",
    "\\end{pmatrix}\n",
    "\\frac{1}{\\sum_{i=1}^{k} \\exp(\\theta_i^t x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "los vectores $\\theta_i$ son pesos que relacionan la muestra $x$ con la clase $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Función costo\n",
    "\n",
    "Teníamos en la logística:     \n",
    "\n",
    "$$J(\\theta) = - \\sum_i \\left ( y^{(i)} \\log h_\\theta (x^{(i)}) + (1-y^{(i)}) \\    log (1-h_\\theta (x^{(i)})) \\right )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reescribimos:     \n",
    "\n",
    "$$J(\\theta) = - \\sum_i \\sum_{k=1}^2 \\mathrm{1}_{\\{y^{(i)} = k\\}} \\log \\left ( \\frac{\\exp(\\theta_{(k)}^t) x^{(i)}}{\\sum_{j=1}^2 \\exp(\\theta_{(j)}^t) x^{(i)}} \\right )  $$\n",
    "\n",
    "* para un dato $x^{(i)}$, sólo sumamos el error de la clase verdadera del dato (función indicadora)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "¡Generalizamos!:\n",
    "$$J(\\theta) = - \\sum_i \\sum_{k=1}^K \\mathrm{1}_{\\{y^{(i)} = k\\}} \\frac{\\exp(\\theta_{(k)}^t) x^{(i)}}{\\sum_{j=1}^2 \\exp(\\theta_{(j)}^t) x^{(i)}}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* el gradiente simplemente es derivar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "representamos el vector \n",
    "![softmax](images/graph_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptrón multicapa\n",
    "* Hasta ahora, todo lo que hicimos fue una variación de la regresión lineal. Entonces el límite de separación entre clases (*decision boundary*) son *hiperplanos*. \n",
    "* ¿Cómo manejamos un problema que no es separable por hiperplanos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [veamos un ejemplo](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=1&regularizationRate=0&noise=0&networkShape=&seed=0.27921&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Una manera de resolver esto es cambiar de espacio hacia uno donde sean linealmente separables las clases.\n",
    "* SVM hace esto con proyecciones implícitas a través de kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* queremos una transformación no-lineal que mueva los datos para luego aplicar softmax: $\\mathrm{softmax}(\\phi(x))$\n",
    "\n",
    "\n",
    "![projection](images/projection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* esto lo podemos hacer agregando una capa adicional: \n",
    "\n",
    "![projection_softmax](images/projection_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Agreguemos una capa al playground anterior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* El entrenamiento, que ajusta los pesos, se puede interpretar como lo siguiente:\n",
    " + en la capa última, los pesos se optimizan para separar las clases con hiperplanos.\n",
    " + en la capa intermedia, los pesos cambian para mejorar la representación de las clases, tal que el softmax tenga un trabajo más sencillo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ¿cómo entrenamos esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* observemos que cada capa es una función:\n",
    "![sof](images/sequence_of_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Calculamos los costos para cada capa:   \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{Costo}}{\\mathrm{Capa}_{n-1}}\n",
    "= \n",
    "\\frac{\\partial \\mathrm{Costo}}{\\mathrm{Capa}_{n}} \n",
    "\\times\n",
    "\\frac{\\partial \\mathrm{Capa}_{n}}{\\mathrm{Capa}_{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Para esto se usa el algoritmo de retropropagación (*backpropagation*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Teorema de aproximación universal\n",
    "* Nos garantiza que con una sola capa oculta de suficiente número de neuronas, podemos representar cualquier función.   \n",
    "\n",
    "* Entonces, un perceptrón multicapa podrá separar cualquier set de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funciones de activación\n",
    "* Una neurona tiene varias entradas y una salida.\n",
    "* La salida es función de la entrada: $\\mathrm{Salida} = \\bar{\\sigma}(\\theta_t x)$\n",
    "* En este contexto $\\sigma$ se llama función de activación. Hasta ahora usamos la función sigmoide, pero hay otras:\n",
    "![activation function](images/activationfunctions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Referencias    \n",
    "Backpropagation: \n",
    "* [Calculus on computational graphs: backpropagation](http://colah.github.io/posts/2015-08-Backprop/), Christopher Olah\n",
    "* [How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html), Michael Nielsen\n",
    "* [What is backpropagation and what is it actually doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U), 3Blue1Brown (video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes neuronales convolucionales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Como vimos hasta ahora, un MLP es de la forma:  \n",
    "$$ y = f_n(f_{n-1}(\\cdot \\cdot f_1(x))) $$\n",
    "Con funciones de la forma:  \n",
    "$$ \n",
    "f(x) = \\begin{pmatrix}\n",
    "\\sigma(\\theta_1^t x) \\\\ \n",
    "... \\\\ \n",
    "\\sigma(\\theta_n^t x)\n",
    "\\end{pmatrix} = \n",
    "\\bar{\\sigma}(\\Theta x)\n",
    "$$\n",
    "\n",
    "* Interpretamos a la última función como el *softmax* que separa con hiperplanos a las clases, y las funciones anteriores como *proyecciones* que obtienen una **buena representación** de los datos para poder separarlos con hiperplanos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Entonces, tiene sentido considerar otras funciones si son más acorde a nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ¿podemos identificar si una imagen es o no de un gato?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![maru the cat](images/marucat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Para usar una MLP podríamos transformar la imagen, que es una matriz de $m\\times n$, en un vector de $m*n$, y luego juntamos unas capas y vemos qué sale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ¡Pero perdemos información! Al transformarlo en un vector y tratar a cada píxel como independiente, no tenemos en cuenta la localidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Podríamos usar funciones que tomen matrices (o tensores si RGB) y tengan en cuenta este aspecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Convolución\n",
    "![matrix convolution example](images/matrix_convolution_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Max-pool\n",
    "![max pool example](images/maxpool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Las convoluciones son formas comunes de procesamiento de imágenes. Se utilizan para encontrar bordes, difuminar o enfocar.  \n",
    "![kernel edge detection](images/kernel_edge_detection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Las operaciones de max-pooling nos dan un cierto grado de invarianza a las traslaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Entonces, tenemos funciones que nos permiten representar a las imágenes de manera invariante a la luminosidad y a la traslación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Convnet architecutres](images/convnet_architecture.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![results](images/cnn_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Referencias\n",
    "* [Introduction to Convolutional Neural Networks](https://cs.nju.edu.cn/wujx/paper/CNN.pdf)\n",
    "* [Convolution and edge detection](http://graphics.cs.cmu.edu/courses/15-463/2005_fall/www/Lectures/convolution.pdf)\n",
    "* [ImageNet classification with Deep CNNs](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "* [Stanford CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes neuronales recurrentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo que hicimos con las redes convolucionales era modificar a la red para que se ajuste mejor a un tipo particular de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "¿Qué podríamos modificar a nuestro MLP si queremos procesar texto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "El problema principal es *la longitud variable* de la entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Como siempre, nos inspiramos en la naturaleza: en vez de tomar toda la entrada de una, tomar de a un caracter o palabra a la vez, y que vayan manteniendo un \"estado interno\" contextual en base a lo que ya vieron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![rnn unrolled](images/RNN-unrolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esto está muy bien, pero tiene un problema: los gradientes se desvanecen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Por ejemplo, si queremos calcular el error en una capa lejana:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{Costo}}{\\partial \\mathrm{Capa}_{n-1}}\n",
    "= \n",
    "\\frac{\\partial \\mathrm{Costo}}{\\partial \\mathrm{Capa}_{n}} \n",
    "\\times\n",
    "\\frac{\\partial \\mathrm{Capa}_{n}}{\\partial \\mathrm{Capa}_{n-1}}\n",
    "\\times\n",
    "\\frac{\\partial \\mathrm{Capa}_{n-1}}{\\partial \\mathrm{Capa}_{n-2}}\n",
    "\\times\n",
    "\\frac{\\partial \\mathrm{Capa}_{n-2}}{\\partial \\mathrm{Capa}_{n-3}}\n",
    "$$\n",
    "\n",
    "Si los coeficientes son menores a uno, decrecen exponencialmente; si son mayores, crecen exponencialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "El módulo recurrente (que toma la salida contextual de la iteración anterior) se puede analizar como si tuviese una capa por cada timestep / iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LSTMs\n",
    "Las redes del tipo Long Short Term Memory (1997) intentan resolver este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![lstm](images/lstm_cec_simple.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GRU \n",
    "Las redes del tipo Gated Recurrent Unit también resuelven el mismo problema. Son un poco más sencillas.\n",
    "\n",
    "$$h_t^j = (1-z_t^j) h_{t-1}^j + z_t^j \\tilde{h}_t^j$$\n",
    "\n",
    "$$\\tilde{h}_t^j = \\tanh(Wx_t + U(r_t \\odot h_{t-1}))^j$$\n",
    "\n",
    "donde $h_t$ es el estado interno en el tiempo $t$, $z_t$ la compuerta de olvido, $\\tilde{h}_t$ es el estado interno candidato, y $r_t$ es la compuerta de reinicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![gru vs lstm](images/gru_lstm_gate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo: BorgesNet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Referencias\n",
    "\n",
    "[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), Christopher Olah   \n",
    "\n",
    "[LSTM: A brief introduction](https://wiki.inf.ed.ac.uk/twiki/pub/MLforNLP/WebHome/lstm_intro.pdf), Daniel Renshaw\n",
    "\n",
    "[Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555.pdf) Junyoung Chung, Yoshua Bengio et al.\n",
    "\n",
    "[The unreasonable effectiveness of recurrent neural networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generativas Adversarias (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* La idea es conseguir modelos generativos.\n",
    "* Tenemos tres componentes:\n",
    " + los datos, que representan la distribución verdadera\n",
    " + el generador, que intenta generar cosas que se parezcan a los datos (i.e., la distribución del generador intenta parecerse a la de los datos)\n",
    " + el discriminador, que dada una entrada dice si es real (proveniente de un dato real) o no (proveniente del generador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comportamiento en teoría de juegos\n",
    "El objetivo de entrenamiento es el siguiente:\n",
    "$$\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)} [ \\log D(x)] + \\mathbb{E}_{z\\sim p_z(z)} [\\log(1-D(G(z)))]$$\n",
    "($z$ es una variable de ruido para pasarle a $G$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![componentes de la gan](images/gan_components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![resultados de gans originales](images/gan_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conditional GANs\n",
    "Idea muy similar, pero la diferencia es que el generador $G$ **toma un dato** y aplica una función sobre ella. El discriminador tiene que decidir si el par (dato, valor de la función) es válido o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![componentes cgan](images/cgan_components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entonces, si tenemos una función $f: A \\rightarrow B$ conocida, podemos armar varias tuplas $(A_i, B_i)$ y entrenar una CGAN para armar $f^{-1}: B \\rightarrow A$!  \n",
    "\n",
    "La función $f$ puede existir o no, pero el punto es que el proceso de $f$ sea bastante sencillo para generar datos, y $f^{-1}$ sea lo difícil. Veamos ejemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![facades with cgan](images/cgan_facade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![cgan night](images/cgan_night.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![occlusion](images/cgan_occlusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Referencias\n",
    "[Image to image translation with conditional adversarial networks](https://arxiv.org/pdf/1611.07004.pdf), Isola et al.\n",
    "\n",
    "[Generative Adversarial Networks](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), Goodfellow et al.\n",
    "\n",
    "[Image to image demo](https://affinelayer.com/pixsrv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Otras cositas\n",
    "\n",
    "* Hay muchos otros tipos de redes y tipos de entrenamiento distintos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Transfer learning**. Cuando se aprovechan los resultados de un entrenamiento anterior sobre datos distintos, para lograr mejores resultados en otro set de datos.   \n",
    "* **Las redes se pueden comprimir**. Una vez entrenado un ensamble de redes neuronales, se pueden comprimir a un solo modelo mejorando los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Bueno, hasta acá tenemos una manera de representar funciones.. a la cual le agregamos memoria (RNN)..\n",
    "* ..como una computadora?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* En 1992 Siegelmann y Sontag mostraron que las RNNs son turing completas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* En 2014, Alex Graves (DeepMind), [publicó](https://arxiv.org/pdf/1410.5401.pdf) un modelo donde una red aprendía algoritmos (copiar vectores, ordenar valores, entre otros). Se vio que su modelo, *Neural Turing Machine*, generalizaba mucho mejor que una red LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* También hay otros modelos que mezclan lo que vimos hasta ahora. Redes que observan imágenes (CNNs) pero de a regiones según les dice una red recurrente (para simular atención),.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hay modelos y técnicas de aprendizaje semi-supervisado (como Q-Learning), donde el objetivo no es conocido pero se tiene una medida de calidad del resultado (como los puntos en un juego)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hay muchos otros tipos! Es realmente un [zoológico](http://www.asimovinstitute.org/neural-network-zoo/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
